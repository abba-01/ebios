# eBIOS v0.2.0 - Release Plan

**Target Release**: Q1 2026 (estimated)
**Theme**: Proof Completion & Production Hardening
**Status**: Planning Phase

---

## Executive Summary

v0.2.0 focuses on completing the formal verification framework and improving production readiness. This release will:
- Complete all Lean 4 formal proofs (from 60% to 100%)
- Improve default configurations for production use
- Add essential middleware (rate limiting)
- Enhance error handling and logging
- Provide containerized deployment

**Breaking Changes**: None (backward compatible with v0.1.0)

---

## Release Goals

### Primary Goals
1. ✅ **Formal Verification Completion** - Complete all 5 remaining Lean 4 proofs
2. ✅ **Production Defaults** - SQLite as default backend (not Memory)
3. ✅ **API Protection** - Rate limiting middleware to prevent abuse
4. ✅ **Developer Experience** - Better error messages and logging
5. ✅ **Deployment** - Docker images for easy deployment

### Secondary Goals
- Performance benchmarking suite
- Enhanced CLI tools
- Improved API documentation
- Migration scripts for v0.1.0 → v0.2.0

---

## Feature Breakdown

### 1. Complete Lean 4 Formal Proofs

**Current State**: 3 complete proofs, 5 skeletons (60% complete)
**Target State**: 8 complete proofs, 0 skeletons (100% complete)

**Proofs to Complete**:

#### 1.1 Enclosure.lean (High Priority)
**Theorem**: Interval arithmetic preserves enclosure property
```lean
theorem enclosure_preservation :
  ∀ (x₁ y₁ x₂ y₂ : ℝ) (u₁ u₂ : ℝ),
  (x₁ ∈ [x₂ - u₂, x₂ + u₂]) ∧ (y₁ ∈ [y₂ - u₂, y₂ + u₂]) →
  (x₁ + y₁) ∈ [(x₂ + y₂) - √(u₁² + u₂²), (x₂ + y₂) + √(u₁² + u₂²)]
```

**Implementation Tasks**:
- [ ] Define interval type in Lean
- [ ] Prove quadrature sum bounds real intervals
- [ ] Prove multiplication preserves enclosure
- [ ] Add test cases for boundary conditions

**Effort**: 2-3 days
**Dependencies**: None

---

#### 1.2 ComposeReduction.lean (High Priority)
**Theorem**: Composition reduces uncertainty
```lean
theorem compose_reduces_uncertainty :
  ∀ (n₁ u₁ n₂ u₂ : ℝ),
  u₁ ≥ 0 → u₂ ≥ 0 → n₁ = n₂ →
  let (_, u_out) := compose n₁ u₁ n₂ u₂
  u_out ≤ min u₁ u₂
```

**Implementation Tasks**:
- [ ] Prove weighted average formula
- [ ] Show denominator is positive
- [ ] Prove uncertainty bound holds
- [ ] Handle edge cases (u₁=0, u₂=0)

**Effort**: 2-3 days
**Dependencies**: None

---

#### 1.3 Complexity.lean (Medium Priority)
**Theorem**: All operations are O(1)
```lean
theorem constant_time_operations :
  ∀ (n₁ u₁ n₂ u₂ : ℝ),
  (time_complexity add) = O(1) ∧
  (time_complexity multiply) = O(1) ∧
  (time_complexity compose) = O(1)
```

**Implementation Tasks**:
- [ ] Define computational complexity in Lean
- [ ] Count primitive operations (add, mul, sqrt)
- [ ] Prove each operation has constant steps
- [ ] Document complexity model

**Effort**: 3-4 days
**Dependencies**: Complexity theory definitions

---

#### 1.4 Monotonicity.lean (Medium Priority)
**Theorem**: Larger uncertainties propagate through operations
```lean
theorem uncertainty_monotonicity :
  ∀ (n₁ n₂ : ℝ) (u₁ u₁' u₂ u₂' : ℝ),
  u₁ ≤ u₁' → u₂ ≤ u₂' →
  let (_, u_out) := add n₁ u₁ n₂ u₂
  let (_, u_out') := add n₁ u₁' n₂ u₂'
  u_out ≤ u_out'
```

**Implementation Tasks**:
- [ ] Prove for addition (quadrature monotonicity)
- [ ] Prove for multiplication (product monotonicity)
- [ ] Prove for composition (weighted average monotonicity)
- [ ] Add counterexample tests for catch/flip

**Effort**: 2 days
**Dependencies**: None

---

#### 1.5 ProofAttestation.lean (Low Priority - Enhancement)
**Current**: Basic attestation structure
**Target**: Complete attestation with verification

**Implementation Tasks**:
- [ ] Add Merkle tree for proof dependencies
- [ ] Implement proof replay verification
- [ ] Add timestamp attestation
- [ ] Create verification CLI tool

**Effort**: 1-2 days
**Dependencies**: All other proofs complete

---

**Total Proof Completion Effort**: 10-14 days

**Deliverables**:
- [ ] 5 complete Lean 4 proofs (no `sorry` statements)
- [ ] Updated proof attestation file
- [ ] Proof verification CI pipeline enhancements
- [ ] Documentation: PROOFS_COMPLETE.md

---

### 2. SQLite as Default Backend

**Current State**: MemoryBackend is default (non-persistent)
**Target State**: SQLiteBackend is default (persistent + ACID)

**Rationale**:
- Production systems need persistence by default
- SQLite provides ACID guarantees
- File-based storage is simpler than LMDB for most use cases
- Backward compatible (can still use Memory backend)

**Implementation Tasks**:

#### 2.1 Backend Improvements
- [ ] Optimize SQLite schema with proper indexes
- [ ] Add connection pooling for concurrent access
- [ ] Implement write-ahead logging (WAL mode)
- [ ] Add automatic vacuum and maintenance
- [ ] Create backend performance tests

**Schema Enhancements**:
```sql
CREATE TABLE IF NOT EXISTS ledger (
    op_id TEXT PRIMARY KEY,
    operation TEXT NOT NULL,
    timestamp TEXT NOT NULL,
    inputs_json TEXT NOT NULL,
    output_json TEXT NOT NULL,
    coverage REAL NOT NULL,
    invariant_passed INTEGER NOT NULL,
    parent_id TEXT,
    entry_hash TEXT NOT NULL,
    signature TEXT NOT NULL,

    -- New indexes for v0.2.0
    CONSTRAINT fk_parent FOREIGN KEY (parent_id) REFERENCES ledger(op_id)
);

CREATE INDEX IF NOT EXISTS idx_timestamp ON ledger(timestamp);
CREATE INDEX IF NOT EXISTS idx_operation ON ledger(operation);
CREATE INDEX IF NOT EXISTS idx_parent_id ON ledger(parent_id);
CREATE INDEX IF NOT EXISTS idx_invariant ON ledger(invariant_passed);
```

#### 2.2 Configuration Management
- [ ] Add `ebios.conf` configuration file
- [ ] Environment variable support (EBIOS_BACKEND, EBIOS_DB_PATH)
- [ ] Automatic database migration on first run
- [ ] Backup and restore utilities

**Configuration File Format** (`ebios.conf`):
```ini
[ledger]
backend = sqlite
db_path = /var/lib/ebios/ledger.db
wal_mode = true
auto_vacuum = incremental

[api]
rate_limit_enabled = true
rate_limit_requests = 100
rate_limit_window = 60

[monitoring]
auto_log = true
halt_on_critical = false
```

#### 2.3 Migration Utilities
- [ ] Create migration script: `scripts/migrate_v0.1_to_v0.2.py`
- [ ] Automatic detection of v0.1.0 data
- [ ] Zero-downtime migration support
- [ ] Rollback capability

**Migration Script**:
```python
#!/usr/bin/env python3
"""
migrate_v0.1_to_v0.2.py

Migrates eBIOS v0.1.0 data to v0.2.0 SQLite backend.
"""

def migrate_memory_to_sqlite(memory_export_path, sqlite_db_path):
    """Migrate from Memory backend export to SQLite"""
    pass

def migrate_sqlite_v0_1_to_v0_2(old_db_path, new_db_path):
    """Migrate SQLite schema from v0.1.0 to v0.2.0"""
    pass
```

**Effort**: 3-4 days

**Deliverables**:
- [ ] Optimized SQLite backend
- [ ] Configuration file system
- [ ] Migration utilities
- [ ] Documentation: SQLITE_BACKEND.md

---

### 3. API Rate Limiting

**Current State**: No rate limiting (vulnerable to abuse)
**Target State**: Configurable rate limiting with multiple strategies

**Implementation Tasks**:

#### 3.1 Rate Limiting Middleware
- [ ] Implement token bucket algorithm
- [ ] Add per-IP rate limiting
- [ ] Add per-endpoint rate limiting
- [ ] Create rate limit response headers

**Implementation**:
```python
# src/nugovern/middleware.py

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
import time
from collections import defaultdict
from threading import Lock

class RateLimiter:
    """
    Token bucket rate limiter

    Limits requests per IP address and per endpoint.
    """

    def __init__(self, requests_per_minute: int = 100):
        self.requests_per_minute = requests_per_minute
        self.tokens = defaultdict(lambda: requests_per_minute)
        self.last_update = defaultdict(time.time)
        self.lock = Lock()

    async def __call__(self, request: Request, call_next):
        client_ip = request.client.host
        endpoint = request.url.path

        with self.lock:
            now = time.time()
            elapsed = now - self.last_update[client_ip]

            # Refill tokens based on time elapsed
            tokens_to_add = elapsed * (self.requests_per_minute / 60.0)
            self.tokens[client_ip] = min(
                self.requests_per_minute,
                self.tokens[client_ip] + tokens_to_add
            )
            self.last_update[client_ip] = now

            # Check if request allowed
            if self.tokens[client_ip] >= 1:
                self.tokens[client_ip] -= 1
                response = await call_next(request)

                # Add rate limit headers
                response.headers["X-RateLimit-Limit"] = str(self.requests_per_minute)
                response.headers["X-RateLimit-Remaining"] = str(int(self.tokens[client_ip]))
                response.headers["X-RateLimit-Reset"] = str(int(now + 60))

                return response
            else:
                # Rate limit exceeded
                return JSONResponse(
                    status_code=429,
                    content={
                        "error": "Rate limit exceeded",
                        "retry_after": 60 - int(elapsed)
                    },
                    headers={
                        "Retry-After": "60",
                        "X-RateLimit-Limit": str(self.requests_per_minute),
                        "X-RateLimit-Remaining": "0"
                    }
                )

# In server.py
from .middleware import RateLimiter

app = FastAPI()
app.middleware("http")(RateLimiter(requests_per_minute=100))
```

#### 3.2 Configuration & Testing
- [ ] Make rate limits configurable via config file
- [ ] Add rate limit bypass for trusted IPs (whitelist)
- [ ] Create rate limit tests
- [ ] Add rate limit metrics

**Effort**: 2 days

**Deliverables**:
- [ ] Rate limiting middleware
- [ ] Configuration options
- [ ] 10+ tests for rate limiting
- [ ] Documentation: API_RATE_LIMITS.md

---

### 4. Enhanced Error Handling

**Current State**: Basic error messages
**Target State**: Detailed, actionable error messages with context

**Implementation Tasks**:

#### 4.1 Structured Error Types
- [ ] Create error type hierarchy
- [ ] Add error codes and categories
- [ ] Include contextual information
- [ ] Add remediation suggestions

**Error Type System**:
```python
# src/nucore/errors.py

from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict, Any

class ErrorCategory(Enum):
    """Error categories for classification"""
    VALIDATION = "validation"
    INVARIANT = "invariant"
    OPERATION = "operation"
    LEDGER = "ledger"
    POLICY = "policy"
    API = "api"

@dataclass
class EBIOSError(Exception):
    """
    Structured error type for eBIOS

    Provides detailed context and remediation suggestions.
    """
    code: str                          # Error code (e.g., "NUCORE_001")
    category: ErrorCategory
    message: str                       # Human-readable message
    details: Optional[str] = None      # Additional details
    context: Optional[Dict[str, Any]] = None  # Contextual data
    remediation: Optional[str] = None  # How to fix

    def to_dict(self) -> Dict[str, Any]:
        return {
            "code": self.code,
            "category": self.category.value,
            "message": self.message,
            "details": self.details,
            "context": self.context,
            "remediation": self.remediation
        }

# Example errors
class InvariantViolationError(EBIOSError):
    """Raised when mathematical invariant is violated"""
    def __init__(self, operation: str, n: float, u: float):
        super().__init__(
            code="NUCORE_001",
            category=ErrorCategory.INVARIANT,
            message=f"Invariant violation in {operation}",
            details=f"Output (n={n}, u={u}) violates invariant u ≥ 0",
            context={"operation": operation, "n": n, "u": u},
            remediation="Check input values and operation implementation"
        )
```

#### 4.2 Enhanced Logging
- [ ] Add structured logging (JSON format)
- [ ] Include operation tracing IDs
- [ ] Add log level configuration
- [ ] Create log aggregation format

**Logging Enhancement**:
```python
# src/nucore/logging_config.py

import logging
import json
from datetime import datetime, UTC

class StructuredLogger:
    """
    JSON-structured logging for eBIOS

    Provides machine-readable logs with context.
    """

    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)

        # JSON formatter
        handler = logging.StreamHandler()
        handler.setFormatter(self._json_formatter())
        self.logger.addHandler(handler)

    def _json_formatter(self):
        class JSONFormatter(logging.Formatter):
            def format(self, record):
                log_data = {
                    "timestamp": datetime.now(UTC).isoformat(),
                    "level": record.levelname,
                    "logger": record.name,
                    "message": record.getMessage(),
                    "module": record.module,
                    "function": record.funcName,
                    "line": record.lineno
                }

                # Add extra fields if present
                if hasattr(record, "operation"):
                    log_data["operation"] = record.operation
                if hasattr(record, "op_id"):
                    log_data["op_id"] = record.op_id

                return json.dumps(log_data)

        return JSONFormatter()

    def info(self, message: str, **context):
        extra = context
        self.logger.info(message, extra=extra)

    def error(self, message: str, **context):
        extra = context
        self.logger.error(message, extra=extra)
```

**Effort**: 2-3 days

**Deliverables**:
- [ ] Structured error types
- [ ] Enhanced logging system
- [ ] Error documentation
- [ ] 15+ error handling tests

---

### 5. Docker Deployment

**Current State**: Manual installation required
**Target State**: Docker images + docker-compose for one-command deployment

**Implementation Tasks**:

#### 5.1 Dockerfile Creation
- [ ] Create production Dockerfile
- [ ] Create development Dockerfile
- [ ] Multi-stage builds for optimization
- [ ] Security hardening

**Production Dockerfile**:
```dockerfile
# Dockerfile

FROM python:3.12-slim as builder

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

FROM python:3.12-slim

WORKDIR /app

# Copy dependencies from builder
COPY --from=builder /root/.local /root/.local

# Copy application
COPY src/ ./src/
COPY governance/ ./governance/
COPY docs/ ./docs/

# Create data directory
RUN mkdir -p /var/lib/ebios

# Environment variables
ENV PYTHONPATH=/app
ENV EBIOS_BACKEND=sqlite
ENV EBIOS_DB_PATH=/var/lib/ebios/ledger.db

# Expose API port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/')" || exit 1

# Run API server
CMD ["python", "-m", "uvicorn", "src.nugovern.server:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 5.2 Docker Compose
- [ ] Create docker-compose.yml for full stack
- [ ] Add volume persistence
- [ ] Include monitoring (optional)
- [ ] Add example environment file

**Docker Compose**:
```yaml
# docker-compose.yml

version: '3.8'

services:
  ebios-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ebios-data:/var/lib/ebios
      - ./governance/policies:/app/governance/policies:ro
    environment:
      - EBIOS_BACKEND=sqlite
      - EBIOS_DB_PATH=/var/lib/ebios/ledger.db
      - EBIOS_RATE_LIMIT=100
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 3s
      retries: 3

volumes:
  ebios-data:
    driver: local
```

#### 5.3 Docker Hub Publishing
- [ ] Create GitHub Actions workflow for Docker builds
- [ ] Tag images with version numbers
- [ ] Publish to Docker Hub or GitHub Container Registry
- [ ] Add README with Docker usage

**GitHub Actions Workflow**:
```yaml
# .github/workflows/docker-publish.yml

name: Docker Build and Push

on:
  push:
    tags:
      - 'v*'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ebios/ebios:latest
            ebios/ebios:${{ github.ref_name }}
```

**Effort**: 2-3 days

**Deliverables**:
- [ ] Production Dockerfile
- [ ] Development Dockerfile
- [ ] docker-compose.yml
- [ ] CI/CD pipeline for Docker builds
- [ ] Documentation: DOCKER_DEPLOYMENT.md

---

## Implementation Timeline

### Phase 1: Formal Proofs (Weeks 1-2)
- Complete Enclosure.lean
- Complete ComposeReduction.lean
- Complete Complexity.lean
- Complete Monotonicity.lean
- Enhance ProofAttestation.lean

**Deliverable**: 100% proof completion

### Phase 2: Production Hardening (Weeks 3-4)
- SQLite default backend
- Rate limiting middleware
- Enhanced error handling
- Configuration system

**Deliverable**: Production-ready defaults

### Phase 3: Deployment (Week 5)
- Docker images
- docker-compose setup
- CI/CD for Docker
- Deployment documentation

**Deliverable**: One-command deployment

### Phase 4: Testing & Documentation (Week 6)
- Integration testing
- Performance benchmarks
- Migration guide
- Updated documentation

**Deliverable**: Release-ready v0.2.0

**Total Timeline**: 6 weeks

---

## Testing Strategy

### Unit Tests
- [ ] Add 20+ new tests for rate limiting
- [ ] Add 15+ new tests for error handling
- [ ] Add 10+ new tests for SQLite backend
- [ ] Maintain 100% test coverage

### Integration Tests
- [ ] Docker container tests
- [ ] Migration script tests
- [ ] End-to-end API tests with rate limiting
- [ ] Performance regression tests

### Performance Benchmarks
- [ ] Ledger append performance (target: <1ms)
- [ ] API endpoint latency (target: <10ms)
- [ ] Rate limiter overhead (target: <100μs)
- [ ] SQLite query performance (target: <5ms for 1000 entries)

---

## Documentation Updates

### New Documentation
- [ ] PROOFS_COMPLETE.md - All formal proofs explained
- [ ] SQLITE_BACKEND.md - SQLite configuration and tuning
- [ ] API_RATE_LIMITS.md - Rate limiting documentation
- [ ] DOCKER_DEPLOYMENT.md - Container deployment guide
- [ ] MIGRATION_v0.1_to_v0.2.md - Upgrade guide

### Updated Documentation
- [ ] Update README.md with v0.2.0 features
- [ ] Update ARCHITECTURE_FINAL.md with new components
- [ ] Update NUGovern_API.md with rate limit headers
- [ ] Update RELEASE_SUMMARY.md for v0.2.0

---

## Breaking Changes

**None** - v0.2.0 is fully backward compatible with v0.1.0

### Migration Path

**From v0.1.0 to v0.2.0**:
1. Install v0.2.0: `pip install --upgrade ebios`
2. Run migration script (optional): `python scripts/migrate_v0.1_to_v0.2.py`
3. Update configuration (optional): Create `ebios.conf`
4. Restart services

**Automatic Migrations**:
- Default backend changes from Memory to SQLite
- First run creates SQLite database automatically
- Existing Memory data can be exported/imported

---

## Success Criteria

### Must Have (Release Blockers)
- [ ] All 8 Lean 4 proofs complete (100%)
- [ ] SQLite as default backend working
- [ ] Rate limiting functional
- [ ] Docker images published
- [ ] All 172 existing tests still passing
- [ ] At least 50 new tests added (total 222+)

### Should Have (High Priority)
- [ ] Migration scripts tested
- [ ] Performance benchmarks passing
- [ ] Documentation complete
- [ ] CI/CD pipeline updated

### Nice to Have (Optional)
- [ ] Helm charts for Kubernetes
- [ ] Prometheus metrics endpoint
- [ ] Admin dashboard
- [ ] Policy editor UI

---

## Risk Assessment

### Technical Risks

**Risk 1: Proof Complexity**
- **Impact**: High
- **Probability**: Medium
- **Mitigation**: Allocate extra time for complex proofs, consult Lean experts

**Risk 2: SQLite Performance**
- **Impact**: Medium
- **Probability**: Low
- **Mitigation**: Performance benchmarks, WAL mode, proper indexing

**Risk 3: Rate Limiting Edge Cases**
- **Impact**: Low
- **Probability**: Medium
- **Mitigation**: Comprehensive testing, configurable bypass

### Schedule Risks

**Risk 1: Proof Completion Delays**
- **Impact**: High
- **Probability**: Medium
- **Mitigation**: Start with proofs first, can release without 100% if needed

**Risk 2: Scope Creep**
- **Impact**: Medium
- **Probability**: Medium
- **Mitigation**: Strict feature freeze, defer non-essential items to v0.3.0

---

## Post-Release Plan

### v0.2.1 (Patch Release)
- Bug fixes from v0.2.0
- Performance optimizations
- Documentation improvements

### v0.3.0 (Next Minor Release)
- JWT authentication
- Basic RBAC
- Prometheus metrics
- Admin API

### v1.0.0 (Production Release)
- Distributed ledger
- LMDB backend
- Mandatory policy signing
- Complete security audit
- Compliance certification

---

## Resources Needed

### Development
- Lean 4 expertise (proofs)
- Python development (backend, API)
- Docker/DevOps expertise
- Testing resources

### Infrastructure
- Docker Hub account
- CI/CD runner time
- Documentation hosting

### Timeline
- 6 weeks development
- 1 week testing
- 1 week release preparation

**Total**: ~8 weeks to v0.2.0 release

---

## Approval & Sign-off

- [ ] Technical Lead: Review and approve
- [ ] Documentation: Review and approve
- [ ] Testing: Review and approve
- [ ] Release Manager: Final sign-off

---

**Version**: v0.2.0 Plan v1.0
**Created**: 2025-10-20
**Status**: Planning Phase
**Next Review**: TBD

---

*This plan is subject to change based on implementation discoveries and stakeholder feedback.*
